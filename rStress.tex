% Options for packages loaded elsewhere
% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  12pt,
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrartcl}
\usepackage{xcolor}
\usepackage{amsmath,amssymb}
\setcounter{secnumdepth}{5}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
  \setmainfont[]{Times New Roman}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother


\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother


% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}



\setlength{\emergencystretch}{3em} % prevent overfull lines

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}



 


\usepackage{tcolorbox}
\usepackage{amssymb}
\usepackage{yfonts}
\usepackage{bm}


\newtcolorbox{greybox}{
  colback=white,
  colframe=blue,
  coltext=black,
  boxsep=5pt,
  arc=4pt}
  
\newcommand{\sectionbreak}{\clearpage}

 
\newcommand{\ds}[4]{\sum_{{#1}=1}^{#3}\sum_{{#2}=1}^{#4}}
\newcommand{\us}[3]{\mathop{\sum\sum}_{1\leq{#2}<{#1}\leq{#3}}}

\newcommand{\ol}[1]{\overline{#1}}
\newcommand{\ul}[1]{\underline{#1}}

\newcommand{\amin}[1]{\mathop{\text{argmin}}_{#1}}
\newcommand{\amax}[1]{\mathop{\text{argmax}}_{#1}}

\newcommand{\ci}{\perp\!\!\!\perp}

\newcommand{\mc}[1]{\mathcal{#1}}
\newcommand{\mb}[1]{\mathbb{#1}}
\newcommand{\mf}[1]{\mathfrak{#1}}

\newcommand{\eps}{\epsilon}
\newcommand{\lbd}{\lambda}
\newcommand{\alp}{\alpha}
\newcommand{\df}{=:}
\newcommand{\am}[1]{\mathop{\text{argmin}}_{#1}}
\newcommand{\ls}[2]{\mathop{\sum\sum}_{#1}^{#2}}
\newcommand{\ijs}{\mathop{\sum\sum}_{1\leq i<j\leq n}}
\newcommand{\jis}{\mathop{\sum\sum}_{1\leq j<i\leq n}}
\newcommand{\sij}{\sum_{i=1}^n\sum_{j=1}^n}
	
\KOMAoption{captions}{tableheading}
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Minimizing fStress and rStress by Majorizing Gauss-Newton},
  pdfauthor={Jan de Leeuw},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\title{Minimizing fStress and rStress by Majorizing Gauss-Newton}
\author{Jan de Leeuw}
\date{February 4, 2026}
\begin{document}
\maketitle
\begin{abstract}
TBD
\end{abstract}

\renewcommand*\contentsname{Table of contents}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{3}
\tableofcontents
}

\sectionbreak

\textbf{Note:} This is a working manuscript which will be
expanded/updated frequently. All suggestions for improvement are
welcome. All Rmd, tex, html, pdf, R, and C files are in the public
domain. Attribution will be appreciated, but is not required. The files
can be found at \url{https://github.com/deleeuw/rStress}

\sectionbreak

\section{Loss Functions}\label{loss-functions}

The Multidimensional Scaling (MDS) loss function fStress is defined as
\begin{equation}
\sigma_f(x):=\frac12\sum_{k=1}^K w_k(f(\delta_k)-f(d_k(x)))^2,\label{eq-fdef}
\end{equation} with \(f\) increasing and differentiable in the open
interval \((0,+\infty)\). In \eqref{eq-fdef} the \(w_k\) are positive
\emph{weights}, the \(\delta_k\) are known \emph{dissimilarities}. The
vector \(x\) has the coordinates of \(n\) points in \(\mathbb{R}^p\),
and the \(d_k(x)\) are Euclidean \emph{distances} between pairs of these
points. For each \(k\) there is a pair of indices \((i,j)\) with
\(1\leq i<j\leq n\) and a matrix \(A_k\) which is the direct sum of
\(p\) copies of \((e_i-e_j)(e_i-e_j)'\), where the \(e_i\) are unit
vectors (columns of the identity matrix of order \(n\)). Thus
\(\smash{d_k(x)=\sqrt{x'A_kx}}\). Metric least squares MDS minimizes
fStress over \(x\).

fStress was introduced and studied in Groenen, De Leeuw, and Mathar
(\citeproc{ref-groenen_deleeuw_mathar_C_95}{1995}). No explicit
algorithm to minimize \eqref(eq-fdef) was given, but the paper has
formulas for the first and second derivatives. De Leeuw
(\citeproc{ref-deleeuw_E_17r}{2017}) uses the multivariate FaÃ  di Bruno
formula to give derivatives of fStress up to order four. These
derivatives can be used in general purpose minimization methods.

An important special case of fStress is rStress (also known as
powerStress), which is \begin{equation}
\sigma_r(x):=\frac12\sum_{k=1}^K w_k(\delta_k^r-d_k^r(x))^2\label{eq-rdef}
\end{equation} Special cases of rStress are Kruskal's stress (Kruskal
(\citeproc{ref-kruskal_64a}{1964a}), Kruskal
(\citeproc{ref-kruskal_64b}{1964b})) with \(r=1\), sstress by Takane,
Young, and De Leeuw (\citeproc{ref-takane_young_deleeuw_A_77}{1977})
with \(r=2\), and the limiting case logarithmic stress with
\(r\rightarrow 0\) by Ramsay (\citeproc{ref-ramsay_77}{1977}). There
have been various attempts to extend the majorization (or MM) method for
MDS (De Leeuw (\citeproc{ref-deleeuw_C_77}{1977})) to rStress.
References and links to various unpublished reports are in De Leeuw
(\citeproc{ref-deleeuw_E_17r}{2017}). The recent smacofx package (Rusch
et al. (\citeproc{ref-rusch_deleeuw_mair_hornik_25}{In Press})) has R
code for the rstressMin() function that implements the majorization
method in De Leeuw, Groenen, and Mair
(\citeproc{ref-deleeuw_groenen_mair_E_16a}{2016}).

Minimizing of either fStress or rStress over \(x\) is a metric MDS
problem. The \(\delta_k\), and consequently the \(f(\delta_k)\), are
\(K\) known numbers. In non-metric MDS the loss function is minimized
over both \(x\) and \(\delta\), where \(\delta\) is constrained to be in
a subset \(\Delta\) of \(\mathbb{R}^K\). For the ordinal version of
non-metric MDS, for example, we require
\(\delta_1\leq\cdots\leq\delta_K\). Since \(f\) is increasing, we can
write fStress simply as \begin{equation}
\sigma_f(x,\delta):=\frac12\sum_{k=1}^K w_k(\delta_k-f(d_k(x)))^2,\label{eq-nmfdef}
\end{equation} where \(\delta\) is no longer a vector of known
dissimilarities, but any vector monotone with the dissimilarities. These
transformed or scaled dissimilarities are often called
\emph{disparities}. Non-metric rStress is simply \eqref{eq-nmfdef} with
\(\smash{f(d_k(x))=d_k^r(x)}\).

In order to exclude the trivial solution with \(x=0\) and \(\delta=0\)
in addition we impose the normalization constraint \begin{equation}
\eta^2(\delta):=\frac12\sum_{k=1}^Kw_k\delta_k^2=1.\label{eq-normal}
\end{equation} This formulation of non-metric MDS can be generalized to
\(\delta\in\Delta\), where \(\Delta\) is a convex cone in
\(\mathbb{R}^K\). This means we require the disparities to be in the
intersection of the cone \(\Delta\) and the sphere \(\Sigma\) defined by
\eqref{eq-normal}.

It is convenient to think of metric MDS as the special case in which the
set \(\Delta\) is the one-element set containing only the normalized
dissimilarities \(\delta\). Alternatively, as in smacof, we can choose
for \(\Delta\) the ray of all vectors that are non-negative multiples of
the dissimilarities. In other words our metric MDS treats the
dissimilarities as measured on a ratio scale.

\section{Algorithm}\label{algorithm}

The technique proposed in this paper to minimize non-metric fStress or
rStress is in the Alternating Least Squares (ALS) family. We start with
an initial estimate \(x^{(0)}\). We then minimize \(\sigma_f\) over
\(\delta\) in \(\Delta\cap\Sigma\) for the current
\(\smash{d(x^{(0)})}\). The minimizer \(\smash{\delta^{(0)}}\) is then
used to minimize fStress over \(x\) for the current disparities,
yielding \(x^{(1)}\). These two steps are alternated until \(x\) and
\(\delta\) do not change any more. Starting in iteration \(\nu=0\) we
compute \begin{subequations}
\begin{align}
\delta^{(\nu)}&=\mathop{\text{argmin}}_{\delta\in\Delta\cap\Sigma}\sigma_f(x^{(\nu)},\delta),\label{eq-als1}\\
x^{(\nu+1)}&=\mathop{\text{argmin}}_x\sigma_f(x,\delta^{(\nu)})\label{eq-als2}.
\end{align}
\end{subequations} We then increase \(\nu\) by one and go into the next
iteration. And so on, until convergence.

\subsection{Normalized Cone
Regression}\label{normalized-cone-regression}

In metric MDS there is no need for the first step \eqref{eq-als1},
because \(\delta^{(\nu)}\) is equal to the normalized dissimilarities
\(\delta\) for all \(\nu\). In the non-metric case step \eqref{eq-als1}
is needed, but compared to \eqref{eq-als2} it is comparatively easy. We
have to compute the least squares projection of \(f(d(x))\) on the cone
\(\Delta\) and then normalize this projection to give it length one. If
\(\Delta\) is the cone of monotone vectors, as in ordinal MDS, the cone
projection is \emph{monotone regression}. The fact that projection on
the intersection of \(\Delta\) and \(\Sigma\) is the same thing as
normalizing the projection on \(\Delta\) is due to De Leeuw
(\citeproc{ref-deleeuw_U_75a}{1975}) and more generally (and more
rigorously) to Bauschke, Bui, and Wang
(\citeproc{ref-bauschke_bui_wang_18}{2018}). Since this step is the same
as in standard MDS algorithms such as smacof (De Leeuw and Mair
(\citeproc{ref-deleeuw_mair_A_09c}{2009}), Mair, Groenen, and De Leeuw
(\citeproc{ref-mair_groenen_deleeuw_A_22}{2022})) we do not go into
details here, and just refer to the literature.

\subsection{Majorization}\label{majorization}

The second step \eqref{eq-als2}, minimizing over \(x\) for fixed current
\(\delta\), is more complicated. There is no analytic solution, similar
to what we have in the first step, and minimization requires an
iterative process of its own. Thus, except in some very special cases,
the second step requires an infinite number of ``inner'' iterations.
Since implmenting an infinite number of iterations is impossible we have
to truncate the inner iteration sequence at some point. In our software
we deviate from the strict ALS framework by not minimizing fStress over
\(x\) for fixed \(\delta\), but by merely taking a single ``inner''
iteration and merely decrease fStress. If this is done judiciously we
still obtain a convergent sequence of updates. This is similar to the
strategy in other MDS algorithms such as smacof (De Leeuw
(\citeproc{ref-deleeuw_C_77}{1977})) and alscal (Takane, Young, and De
Leeuw (\citeproc{ref-takane_young_deleeuw_A_77}{1977})).

In smacof the inner iteration step is a majorization step, by now more
commonly known as an MM step. Briefly, we find a function
\(\kappa_f(x;y)\) such that

\begin{itemize}
\tightlist
\item
  \(\kappa_f(x,y)\leq\sigma_f(x)\) for all \(x\) and \(y\) in \(\Xi\),
  and
\item
  \(\kappa_f(x;y)=\sigma_f(x)\) if and only if \(x=y\).
\end{itemize}

An inner iteration is of the form \begin{equation}
x^{(\mu+1)}=\mathop{\text{argmin}}_{x\in\Xi}\kappa(x,x^{(\mu)}).\label{eq-inner}
\end{equation} If \(x^{(\mu+1)}=x^{(\mu)}\) we declare convergence and
stop. From \eqref{eq-inner}, \begin{equation}
\sigma_f(x^{(\mu+1)})\leq\kappa_f(x^{(\mu+1)},x^{(\mu)})<\kappa_f(x^{(\mu)},x^{(\mu)})=\sigma_f(x^{(\mu)}).
\label{eq-sandwich}
\end{equation} Thus an inner majorization step upgrading \(x\) for given
\(\delta\) decreases fStress (unless we stop). Remember that in ALS the
inner iterative process (indexed by \(\mu\)) goes on within step 2 of
the ``outer'' update (indexed by \(\nu\)).

In De Leeuw, Groenen, and Mair
(\citeproc{ref-deleeuw_groenen_mair_E_16a}{2016}) a majorization method
was proposed to minimize rStress. It majorizes \(d^r\) as a function of
\(x\), and for this it uses the specific properties of the power
function. It consequently cannot be used for fStress. The technique is
incorporated in the smacofx R package, and numerical experience
indicates it works, but convergence can be painfully slow. Because of
the generality of the function \(f\) (any differentiable increasing
function) it seems impossible to develop an majorization method for
fStress along the same lines as the one for rStress. Consequently we go
a somewhat different route in this paper. We do not only deviate from
the strict ALS procedure by only partially minimizing loss over \(x\)
for fixed \(d\), we also deviate from the strict majorization approach
by majorizing an approximation of fStress.

In deriving the approximation and majorization we surpress the
dependency of fStress on \(\delta\), because in the second ALS substep
\(\delta\) is just a vector of constants. We first approximate
\(f(d(x))\) near \(d(y)\) with \begin{equation}
f(d_k(x))\approx f(d_k(y))+\mathcal{D}f(d_k(y))(d_k(x)-d_k(y)).\label{eq-taylor}
\end{equation} Define \begin{equation}
\omega_f(x;y):=\sum_{k=1}^K w_k(f(\delta_k)-f(d_k(y))-\mathcal{D}f(d_k(y))(d_k(x)-d_k(y)))^2,\label{eq-defeta}
\end{equation} Note that in \eqref{eq-taylor} the derivative is with
respect to \(d\), not with respect to \(x\) or \(y\). This is a major
difference with the majorizations in De Leeuw, Groenen, and Mair
(\citeproc{ref-deleeuw_groenen_mair_E_16a}{2016}).

Note that \(\omega_f(x;x)=\sigma_f(x)\) for all \(x\) and if \(f\) is
the identity then \(\omega_f(x;y)=\sigma_f(x)\) for all \(x\) and \(y\).
If \(f\) is linear with intercept \(\beta\) and slope \(\alpha\) then
\begin{equation}
\omega_f(x,y)=a^2\sum_{k=1}^Kw_k(\delta_k-d_k(x))^2=a^2\sigma_r(x),\label{eq-linear}
\end{equation} with \(r=1\).

We now give an alternative and more convenient expression for
\(\omega_f(x,y)\). Define \begin{subequations}
\begin{align}
\tilde w_k(y)&:=w_k\{\mathcal{D}f(d_k(y))\}^2,\label{eq-tildew}\\
\tilde\delta_k(y)&:=\frac{f(\delta_k)-f(d_k(y))}{\mathcal{D}f(d_k(y))}+d_k(y).\label{eq-tilded}
\end{align}
\end{subequations} Then \begin{equation}
\omega_f(x;y)=\sum_{k=1}^K\tilde w_k(y)(\tilde\delta_k(y)-d_k(x))^2.\label{eq-omegas}
\end{equation} We see from \eqref{eq-tildew} that \(\tilde w_k(y)\) is
always non-negative and from \eqref{eq-tilded} that
\(\tilde\delta_k(y)\) can be negative if \(d_k(y)>\delta_k\). For convex
\(f\), however, we have \begin{equation}
\tilde\delta_k(y)=\frac{f(\delta_k)-f(d_k(y))}{\mathcal{D}f(d_k(y))}+d_k(y)\geq d_k(x)\geq 0.\label{eq-convex}
\end{equation}

For rStress equations \eqref{eq-tildew} and \eqref{eq-tilded} become
\begin{subequations}
\begin{align}
\tilde w_k(y)&:=r^2w_kd_k^{2(r-1)}(y),\label{eq-tildewr}\\
\tilde\delta_k(y)&:=\frac{\delta_k^r+(r-1)d_k^r(y)}{rd_k^{r-1}(y)}.\label{eq-tildedr}
\end{align}
\end{subequations} By convexity \(\tilde\delta_k(y)\) is non-negative if
\(r\geq 1\). For \(0<r<1\) we have \(\tilde\delta_k(y)>0\) if and only
if \(\smash{d_k(y)<(1-r)^r\delta_k}\). If \(\delta_k>d_k(y)\) then
\(\tilde\delta_k(y)>d_k(y)\geq 0\).

By writing \(\omega_f(x,y)\) as in \eqref{eq-omegas} we are on familiar
majorization terrain. If \(\delta_k(y)>0\) we use Cauchy-Schwartz, as in
standard smacof, \begin{subequations}
\begin{equation}
d_k(x)\geq\frac{1}{d_k(y)}\text{tr}\ x'A_ky,\label{eq-cs}
\end{equation}
and if $\delta_k(y)<0$ we use the arithmetic mean/geometric mean (AM/GM) inequality
in the form
\begin{equation}
d_k(x)\leq\frac12\frac{1}{d_k(y)}\{y'A_ky+x'A_kx\},\label{eq-amgm}
\end{equation}
\end{subequations} Use of the AM/GM inequality for majorizing terms with
negative dissimilarities was pioneered by Heiser
(\citeproc{ref-heiser_91}{1991}).

Define the matrices \begin{subequations}
\begin{align}
V(y)&:=\sum_{k=1}^K\tilde w_k(y)A_k,\\
B(y)&:=\sum_{\tilde\delta_k(y)>0}\tilde w_k\frac{\tilde\delta_k(y)}{d_k(y)}A_k,\\
H(y)&:=\sum_{\tilde\delta_k(y)<0}\tilde w_k\frac{\tilde\delta_k(y)}{d_k(y)}A_k.
\end{align}
\end{subequations} Note that all three matrices (more preecisely
matrix-valued functions) are positive semi-definite. We can use these
matrices for a majorization of \(\omega_f(x;y)\) at \(y\) is
\begin{equation}
\omega_f(x;y)=C+\frac12 x'(V(y)+H(y))x-x'B(y)x\leq\kappa_f(x;y),\label{eq-matmajx}
\end{equation} with \begin{equation}
\kappa_f(x;y):=C+\frac12 x'(V(y)+H(y))x-x'B(y)y,\label{eq-matmajy}
\end{equation} where \(C\) is a constant that depends on \(y\) but not
on \(x\).

We now update using \[
x^{(\mu+1)}=\mathop{\text{argmin}}_x\kappa_f(x;x^{(\mu)})=(V(x^{(\mu)})+H(x^{(\mu)}))^+B(x^{(\mu)})x^{(\mu)},
\] which results in \[
\sigma_f(x^{(\mu+1)})\approx\omega_f(x^{(\mu+1)};x^{(\mu)})\leq\kappa_f(x^{(\mu+1)};x^{(\mu)})<\kappa_f(x^{(\mu)};x^{(\mu)})=\sigma_f(x^{(\mu)}).
\] Unlike in smacof there is no guarantee that \(\sigma_f\) decreases
from one iteration to the other. Monotone convergence of loss function
values will only happen if the approximation is good, i.e.~if
\(d(x^{(\mu+1)}\) is close to \(d_k(x^{(\mu)}\). This requires closer
monitoring of convergence than in smacof. Also note that if
\(\tilde\delta_k(y)<0\) for all \(k\) then \(B(y)=0\), which means that
the update from \(y\) is equal to zero. Again, this eventuality must be
monitored.

\section{Software}\label{software}

\subsection{Data}\label{data}

The data and weights are in the MDS data format defined in De Leeuw
(\citeproc{ref-deleeuw_E_25b}{2025}). This is a list with two scalars
nobj and ndat, the number of objects and the number of data points
(object pairs), and five vectors iind, jind, delta, blocks, weights of
length ndat. Vectors iind and jind have integers between 1 and n with
iind \textgreater{} jind that code for which pairs of objects we have
dissimlarity information. The dissimilarities are in delta, the weights
in weights. Dissimilarities are sorted in increasing order and blocks
indicates tie-blocks in the dissimilarities.

In smacofSSRStress.R there is a function smacofSSRStress() which sets up
the parameters for a call to smacofSSRStressEngine(), which is coded in
C and can be found in the shared library smacofSSRStress.so.

The arguments of smacofSSRStress.R are

\begin{verbatim}
function (theData, ndim = 2, xinit = NULL, ties = 1, itmax = 1000, 
    eps = 1e-06, rpow = 1, digits = 8, width = 10, verbose = TRUE, 
    weighted = FALSE, ordinal = FALSE) 
NULL
\end{verbatim}

\subsection{Initial Estimate}\label{initial-estimate}

The initial estimate of the configuration is calculated using classical
MDS (also known as Torgerson-Gower MDS) on the dissimilarities. First we
make sure the weights add up to one. If there are missing
dissimilarities they are first imputed by setting them equal to the
weighted mean of the non-missing dissimilarities. Then we double center
the squared dissimilarities and compute the classical scaling solution
using the eigs\_sym() function from the RSpectra package (Qiu and Mei
(\citeproc{ref-qiu_mei_24}{2024})).

Now we scale the solution, which is done with the R function
smacofSSRStressScale(). We first normalize the powered dissimilarities
such that their weighted sum of squares is equal to one. We then choose
\(\lambda\) to minimize \[
\sigma(\lambda):=\sum_k w_k(\delta_k^r-d_k^r(\lambda x))^2=\sum_k w_k(\delta_k^r-\lambda^rd_k^r(x))^2,
\] where \(x\) is the Torgerson-Gower solution. The minimum is attained
for \[
\hat\lambda:=\left[\frac{\sum_k w_k\delta_k^rd_k^r(x)}{\sum_kw_kd_k^{2r}(x)}\right]^{1/r}.
\] Our initial estimate is \(\hat\lambda x\) wit distances
\(\hat\lambda d_k(x)\).

\section{Examples}\label{examples}

\section*{References}\label{references}
\addcontentsline{toc}{section}{References}

\phantomsection\label{refs}
\begin{CSLReferences}{1}{0}
\bibitem[\citeproctext]{ref-bauschke_bui_wang_18}
Bauschke, Heinz H., Minh N. Bui, and Xianfu Wang. 2018. {``{Projecting
onto the Intersection of a Cone and a Sphere}.''} \emph{SIAM Journal on
Optimization} 28: 2158--88.

\bibitem[\citeproctext]{ref-deleeuw_U_75a}
De Leeuw, Jan. 1975. {``{A Normalized Cone Regression Approach to
Alternating Least Squares Algorithms}.''} Department of Data Theory
FSW/RUL.
\url{https://jansweb.netlify.app/publication/deleeuw-u-75-a/deleeuw-u-75-a.pdf}.

\bibitem[\citeproctext]{ref-deleeuw_C_77}
---------. 1977. {``Applications of Convex Analysis to Multidimensional
Scaling.''} In \emph{Recent Developments in Statistics}, edited by J. R.
Barra, F. Brodeau, G. Romier, and B. Van Cutsem, 133--45. Amsterdam, The
Netherlands: North Holland Publishing Company.

\bibitem[\citeproctext]{ref-deleeuw_E_17r}
---------. 2017. {``{Higher Partials of fStress. Who Needs Them ?}''}
2017.
\url{https://jansweb.netlify.app/publication/deleeuw-e-17-r/deleeuw-e-17-r.pdf}.

\bibitem[\citeproctext]{ref-deleeuw_E_25b}
---------. 2025. {``Yet Another Smacof - Square Symmetric Case.''} 2025.
\url{https://jansweb.netlify.app/publication/deleeuw-e-25-b/}.

\bibitem[\citeproctext]{ref-deleeuw_groenen_mair_E_16a}
De Leeuw, Jan, Patrick Groenen, and Patrick Mair. 2016. {``{Minimizing
rStress Using Majorization}.''} 2016.
\url{https://jansweb.netlify.app/publication/deleeuw-groenen-mair-e-16-a/deleeuw-groenen-mair-e-16-a.pdf}.

\bibitem[\citeproctext]{ref-deleeuw_mair_A_09c}
De Leeuw, Jan, and Patrick Mair. 2009. {``{Multidimensional Scaling
Using Majorization: SMACOF in R}.''} \emph{Journal of Statistical
Software} 31 (3): 1--30.
\url{https://www.jstatsoft.org/article/view/v031i03}.

\bibitem[\citeproctext]{ref-groenen_deleeuw_mathar_C_95}
Groenen, Patrick J. F., Jan De Leeuw, and Rudolf Mathar. 1995. {``{Least
Squares Multidimensional Scaling with Transformed Distances}.''} In
\emph{{From Data to Knowledge: Theoretical and Practical Aspects of
Classification, Data Analysis and Knowledge Organization}}, edited by W.
Gaul and D. Pfeifer. Berlin, Germany: Springer Verlag.
\url{https://jansweb.netlify.app/publication/groenen-deleeuw-mathar-c-95/groenen-deleeuw-mathar-c-95.pdf}.

\bibitem[\citeproctext]{ref-heiser_91}
Heiser, W. J. 1991. {``{A Generalized Majorization Method for Least
Squares Multidimensional Scaling of Pseudodistances that May Be
Negative}.''} \emph{Psychometrika} 56 (1): 7--27.

\bibitem[\citeproctext]{ref-kruskal_64a}
Kruskal, Joseph B. 1964a. {``{Multidimensional Scaling by Optimizing
Goodness of Fit to a Nonmetric Hypothesis}.''} \emph{Psychometrika} 29:
1--27.

\bibitem[\citeproctext]{ref-kruskal_64b}
---------. 1964b. {``{Nonmetric Multidimensional Scaling: a Numerical
Method}.''} \emph{Psychometrika} 29: 115--29.

\bibitem[\citeproctext]{ref-mair_groenen_deleeuw_A_22}
Mair, Patrick, Patrick J. F. Groenen, and Jan De Leeuw. 2022. {``{More
on Multidimensional Scaling in R: smacof Version 2}.''} \emph{Journal of
Statistical Software} 102 (10): 1--47.
\url{https://www.jstatsoft.org/article/view/v102i10}.

\bibitem[\citeproctext]{ref-qiu_mei_24}
Qiu, Yixuan, and Jiali Mei. 2024. \emph{{RSpectra: Solvers for
Large-Scale Eigenvalue and SVD Problems}}.
\url{https://CRAN.R-project.org/package=RSpectra}.

\bibitem[\citeproctext]{ref-ramsay_77}
Ramsay, James O. 1977. {``{Maximum Likelihood Estimation in
Multidimensional Scaling}.''} \emph{Psychometrika} 42: 241--66.

\bibitem[\citeproctext]{ref-rusch_deleeuw_mair_hornik_25}
Rusch, Thomas, Jan De Leeuw, Patrick Mair, and Kurt Hornik. In Press.
{``Flexible Multidimensional Scaling with the r Package Smacofx.''}
\emph{Journal of Statistical Software}, In Press.
\url{https://jansweb.netlify.app/publication/rusch-deleeuw-mair-hornik-a-25/rusch-deleeuw-mair-hornik-a-25.pdf}.

\bibitem[\citeproctext]{ref-takane_young_deleeuw_A_77}
Takane, Yoshio, Forrest W. Young, and Jan De Leeuw. 1977. {``Nonmetric
Individual Differences in Multidimensional Scaling: An Alternating Least
Squares Method with Optimal Scaling Features.''} \emph{Psychometrika}
42: 7--67.

\end{CSLReferences}




\end{document}
